from langchain_community.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain_community.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings  # HuggingFace ì„ë² ë”©ì„ ì‚¬ìš©
from langchain_core.runnables import RunnableLambda
from langchain.prompts import PromptTemplate
import json
import os
import gradio as gr
from dotenv import load_dotenv
import ngrok
import httpx
import re
import ast
import asyncio

# .env íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ API í‚¤ ë¡œë“œ
load_dotenv()  # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
with open("./keys/openai_key.txt", "r") as file:
    OPENAI_API_KEY = file.read().strip()

llm = ChatOpenAI(temperature=1.0, model='gpt-4o-mini', openai_api_key=OPENAI_API_KEY)

# HuggingFace ì„ë² ë”© ì •ì˜ (ëª¨ë¸ ì´ë¦„ì„ ì „ë‹¬)
model_name = "all-MiniLM-L6-v2"
embeddings = HuggingFaceEmbeddings(model_name=model_name)

# FAISS ë²¡í„° DB ë¡œë“œ (HuggingFace ì„ë² ë”© ì‚¬ìš©)
vector_db = FAISS.load_local("./vectorstore/blender_vector_db", embeddings, allow_dangerous_deserialization=True)


# blender ì´ë¯¸ì§€, ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
image_path = "C:/blender-mcp/image"
model_path = "C:/blender-mcp/model"

for folder_path in [image_path, model_path]:
    # í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
        print(f"í´ë” '{folder_path}'ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print(f"í´ë” '{folder_path}'ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")


# model ì„œë²„ ê²½ë¡œ
txt2img_url = "https://15d8-34-32-134-37.ngrok-free.app/image2text"
txt2obj_url = "https://8343-34-71-148-149.ngrok-free.app/generate"
img2txt_url = ""
mcp_url = "http://172.17.0.57:45432/run"


# LLM ì‘ë‹µ ì²˜ë¦¬
async def response(message, history):  # ê¸°ë³¸ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •

    # history_langchain_formatì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ê¸°ë¡ì„ ì €ì¥
    history_langchain_format = []
    

    #============== R A G ==============

    ## step 1 - select fn_call
   
    # ì§ˆë¬¸ê³¼ retrieved_docsë¥¼ í¬í•¨í•˜ëŠ” í…œí”Œë¦¿ ìƒì„±
    template = """
    You are a coder for Blender Python program.
    Analyze the question and respond with the appropriate `fn_call` that matches the request.
    The `fn_call` should be provided with no explanation or additional details, only the function name.

    question: {question},

    fn_call: [
        rag_normal(ê¸°ë³¸ ë„í˜•ì„ ê°€ì§€ê³  ëª¨ë¸ì„ ë§Œë“­ë‹ˆë‹¤. ê°„ë‹¨í•œ ëª¨ë¸ë§ì— ì í•©í•©ë‹ˆë‹¤.),
        rag_del(ëª¨ë“  ì‘ì—…ë¬¼ì„ ì‚­ì œí•˜ê³  ì´ˆê¸°í™”í•©ë‹ˆë‹¤.),
        rag_mesh(3d ì˜¤ë¸Œì íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ ì ìš©í•©ë‹ˆë‹¤. ì •êµí•˜ê³  ë³µì¡í•œ 3d ì˜¤ë¸Œì íŠ¸ë¡œ ë³€ê²½ìš”ì²­í–ˆì„ ë•Œ ì í•©í•©ë‹ˆë‹¤.),
        rag_texture(í…ìŠ¤ì³ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ì ìš©í•©ë‹ˆë‹¤. ì´ë¯¸ ëª¨ë¸ì„ ë§Œë“¤ê³  ìˆëŠ” ìƒí™©ì—ì„œ ì‚¬ìš©ìê°€ í…ìŠ¤ì³ë§Œ ë³„ë„ë¡œ ìƒì„± ìš”ì²­í–ˆì„ ë•Œ ì í•©í•©ë‹ˆë‹¤.),
        
        nomal(ë¸”ëœë” ì½”ë“œì‘ì„±ê³¼ ê´€ë ¨ì—†ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ë¶„ë¥˜í•˜ê¸° ì–´ë ¤ìš°ë©´ ì´ fn_callë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤.)
    ]

    answer:
    """
    # 

    # PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ í…œí”Œë¦¿ì„ ì²˜ë¦¬
    prompt_template = PromptTemplate(input_variables=["question"], template=template)

    # LLMChain ê°ì²´ ìƒì„±
    step_1_llm_chain = LLMChain(llm=llm, prompt=prompt_template)

    # step_1_formatted_prompt ìƒì„±: í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©
    step_1_formatted_prompt = prompt_template.format(question=message)

    # LLMChain ì‹¤í–‰
    fn_call = step_1_llm_chain.run(question=message)

    print(f"ìš”ì²­ì‚¬í•­ : {message}, fn_call : {fn_call}")


    ## step 2 - run fn_call

    if "rag_nomal" in fn_call:
        # ë²¡í„° DBì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
        search_results = search_in_db(message, vector_db)

        # ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        retrieved_docs = "\n".join([result.page_content for result in search_results]) 

        # ì§ˆë¬¸ê³¼ retrieved_docsë¥¼ í¬í•¨í•˜ëŠ” í…œí”Œë¦¿ ìƒì„±
        template = """
        You are coder for Blender python program.
        questionì„ ë¶„ì„í•˜ê³ , ìµœì í™”ëœ blender python scriptë¥¼ ì œì‘í•˜ì„¸ìš”.
        objectëª…ì¹­ì€ ê° ëª¨ë¸ë§ ìš”ì†Œì— ë§ê²Œ ì •í™•í•œ ëª…ì¹­ìœ¼ë¡œ ì œì‘í•´ì£¼ì„¸ìš”.
        retrieved_docsëŠ” Blender python scriptì˜ ê¸°ìˆ ë¬¸ì„œì…ë‹ˆë‹¤. ì°¸ê³ í•˜ë˜ ê´€ë ¨ì„±ì´ ì—†ë‹¤ë©´ ë¬´ì‹œí•´ë„ ë©ë‹ˆë‹¤.
        question : {question},
        retrieved_docs : {retrieved_docs},
        answer:
        """

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í…œí”Œë¦¿ ì ìš©
        formatted_prompt = template.format(question=message, retrieved_docs=retrieved_docs)

    elif "rag_del" in fn_call:
        template = """
        You are a coder for Blender Python program.
        questionì„ ë¶„ì„í•˜ì—¬ ì´ë¯¸ ìƒì„±ëœ blender ëª¨ë¸ì—ì„œ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë¶€ë¶„ì„ ì‚­ì œí•˜ëŠ” scriptë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. 
        ì „ì²´ ì‚­ì œë¥¼ ì›í•  ê²½ìš° ì „ì²´ ëª¨ë¸ì„ ì‚­ì œí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

        question: {question},

        answer:
        """

        formatted_prompt = template.format(question=message)

    elif "rag_texture" in fn_call:
        template = """
        ë‹¹ì‹ ì€ Blenderì—ì„œ ì˜¤ë¸Œì íŠ¸ì— í…ìŠ¤ì²˜ë¥¼ ìƒì„±í•˜ëŠ” text-to-image ëª¨ë¸ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“œëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ í•„ìš”í•œ í…ìŠ¤ì²˜ íŒŒì¼ëª…ì„ ì˜¤ë¸Œì íŠ¸ ëª…ì— ë§ê²Œ ì—°ê´€ ì§€ì–´ ìƒì„±í•˜ì„¸ìš”.
        ê° íŒŒì¼ëª…ì— ëŒ€í•´ ìµœì í™”ëœ í…ìŠ¤ì²˜ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ë˜, ì—¬ëŸ¬ ê°œì˜ í…ìŠ¤ì²˜ê°€ í•„ìš”í•œ ê²½ìš°ì—ëŠ” íŒŒì¼ëª….png : í”„ë¡¬í”„íŠ¸ í˜•íƒœë¡œ ë”•ì…”ë„ˆë¦¬ë¡œ ë§¤ì¹­ì‹œì¼œ ì£¼ì„¸ìš”.
        ìµœì¢… ì¶œë ¥ì€ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ì–´ì•¼ í•˜ë©°, ê·¸ ì™¸ì˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        ### 3D í…ìŠ¤ì²˜ ìƒì„± ì›ì¹™:
        - **ì¬ì§ˆ (Material)**: í…ìŠ¤ì²˜ì˜ ê¸°ë³¸ ì¬ì§ˆì„ ì„¤ì •í•©ë‹ˆë‹¤. (ì˜ˆ: ëŒ, ê¸ˆì†, ë‚˜ë¬´, íŒ¨ë¸Œë¦­ ë“±)
        - **ë¶„ìœ„ê¸° (Style & Mood)**: í…ìŠ¤ì²˜ì˜ ëŠë‚Œì„ ì„¤ëª…í•©ë‹ˆë‹¤. (ì˜ˆ: ì–´ë‘ìš´, ì‹ ë¹„ë¡œìš´, ì›…ì¥í•œ ë“±)
        - **ìƒ‰ìƒ (Color Palette)**: ì£¼ìš” ìƒ‰ìƒ ì¡°í•©ì„ ë¬˜ì‚¬í•©ë‹ˆë‹¤. (ì˜ˆ: ì–´ë‘ìš´ íšŒìƒ‰, ê¸ˆì†ì ì¸ ëŠë‚Œ)
        - **ì„¸ë¶€ í‘œí˜„ (Details)**: í‘œë©´ ì§ˆê°, ì¡°ëª… íš¨ê³¼, í•´ìƒë„ ë“±ì„ ì¶”ê°€í•˜ì—¬ í…ìŠ¤ì²˜ì˜ íŠ¹ì§•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.
        - **ìµœì¢… í˜•ì‹ (Output Format)**: text-to-image AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡, í…ìŠ¤ì²˜ì— ëŒ€í•œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ì„¤ëª…ì„ ì œê³µí•©ë‹ˆë‹¤.

        ---

        **ì˜ˆì‹œ (ì°¸ê³ ìš©)**:
        ì‚¬ìš©ì ìš”ì²­ : "create magic stone gate"
        ê°€ëŠ¥í•œ í”„ë¡¬í”„íŠ¸: "A mystical ancient stone gate texture, glowing runes, moss-covered surface, cinematic lighting."

        ---

        question: {question},

        answer:
        """
        
        # PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ í…œí”Œë¦¿ì„ ì²˜ë¦¬
        prompt_template = PromptTemplate(input_variables=["question"], template=template)

        # LLMChain ê°ì²´ ìƒì„±
        step_2_llm_chain = LLMChain(llm=llm, prompt=prompt_template)

        # step_2_formatted_prompt ìƒì„±: í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©
        step_2_formatted_prompt = prompt_template.format(question=message)

        # LLMChain ì‹¤í–‰
        texture_dict = step_2_llm_chain.run(question=message)

        print(f"txt2img ìš”ì²­ : {texture_dict}")

        
        # ë¬¸ìì—´ì—ì„œ '{}' ë¶€ë¶„ë§Œ ì¶”ì¶œ
        start_index = texture_dict.find('{')  # ì²« ë²ˆì§¸ '{'ì˜ ì¸ë±ìŠ¤
        end_index = texture_dict.rfind('}')  # ë§ˆì§€ë§‰ '}'ì˜ ì¸ë±ìŠ¤

        if start_index != -1 and end_index != -1 and start_index < end_index:
            dict_str = texture_dict[start_index:end_index + 1]  # '{'ì™€ '}' ì‚¬ì´ì˜ ë¬¸ìì—´ ì¶”ì¶œ
            try:
                # ì¶”ì¶œí•œ ë¬¸ìì—´ì„ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                texture_dict = ast.literal_eval(dict_str)
                print("ì¶”ì¶œëœ ë”•ì…”ë„ˆë¦¬:", texture_dict)
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            try:
                # ë§Œì•½ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ì´ë¼ë©´ ê·¸ëŒ€ë¡œ ì²˜ë¦¬
                texture_dict = ast.literal_eval(texture_dict)
                print("ë”•ì…”ë„ˆë¦¬:", texture_dict)
            except Exception as e:
                print(f"ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")

        # ë”•ì…”ë„ˆë¦¬ ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
        first_key = list(texture_dict.keys())[0]
        first_value = texture_dict[first_key]

        data = {
            "prompt": first_value
        }

        save_path = os.path.join(image_path, first_key)
        response = await txt2img_request(txt2img_url, data, save_path)


        template = """
        You are coder for Blender python program.
        questionì„ ë¶„ì„í•˜ê³ , ìµœì í™”ëœ blender python scriptë¥¼ ì œì‘í•˜ì„¸ìš”.
        objectëª…ì¹­ì€ ê° ëª¨ë¸ë§ ìš”ì†Œì— ë§ê²Œ ì •í™•í•œ ëª…ì¹­ìœ¼ë¡œ ì œì‘í•´ì£¼ì„¸ìš”.
        í…ìŠ¤ì³ íŒŒì¼ ê²½ë¡œì˜ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì—¬ ì˜¤ë¸Œì íŠ¸ì— ì í•©í•œ í…ìŠ¤ì³ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì½”ë“œì— í…ìŠ¤ì³ë¶€ë¶„ ê²½ë¡œë¥¼ ì ìš©í•´ì£¼ì„¸ìš”.

        question : {question},
        texture path : {texture_path} 

        answer:
        """

        formatted_prompt = template.format(question=message, texture_path = save_path)

    elif "rag_mesh" in fn_call:

        template = """
        You are an expert coder for Blender Python scripts.

        Your goal is to analyze the user's question and generate an optimized Blender Python script that **creates geometry using mesh data directly**, instead of relying on primitive shapes like cubes, spheres, or cylinders.

        When appropriate, **manually define vertices, edges, and faces to construct complex or custom models** via `bpy.data.meshes.new()` and `from_pydata()`.

        Use precise object naming that matches the modeling elements and anatomical or functional intent.

        You may reference the retrieved_docs for Blender API details, but ignore unrelated information.

        If the user asks for a model resembling a real-world object (e.g. human, tree, robot), generate a mesh structure that reflects its geometry with realistic proportionsâ€”even in low-poly formâ€”rather than assembling primitives.

        question: {question}

        answer:
        """


        formatted_prompt = template.format(question=message)



        '''

        template = """
        ë‹¹ì‹ ì€ Blenderì—ì„œ ì˜¤ë¸Œì íŠ¸ meshë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŒì´ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ í•„ìš”í•œ mesh ì˜¤ë¸Œì íŠ¸ ëª…ì„ ì¶œë ¥í•˜ì„¸ìš”.
        ìµœì¢… ì¶œë ¥ì€ ì˜¤ë¸Œì íŠ¸ ì´ë¦„ì´ë©°, ê·¸ ì™¸ì˜ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        question: {question},

        answer:
        """
        
        # PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ í…œí”Œë¦¿ì„ ì²˜ë¦¬
        prompt_template = PromptTemplate(input_variables=["question"], template=template)

        # LLMChain ê°ì²´ ìƒì„±
        step_2_llm_chain = LLMChain(llm=llm, prompt=prompt_template)

        # step_2_formatted_prompt ìƒì„±: í…œí”Œë¦¿ì—ì„œ ì‚¬ìš©í•  ë³€ìˆ˜ë¥¼ ì „ë‹¬í•˜ì—¬ ì‚¬ìš©
        step_2_formatted_prompt = prompt_template.format(question=message)

        # LLMChain ì‹¤í–‰
        obj_name = step_2_llm_chain.run(question=message)

        print(f"txt2mesh ìš”ì²­ : {obj_name}")
        
        save_path = os.path.join(model_path, obj_name)
        response = await obj_generate_request(txt2obj_url, obj_name, save_path)


        template = """
        You are coder for Blender python program.
        questionì„ ë¶„ì„í•˜ê³ , ìµœì í™”ëœ blender python scriptë¥¼ ì œì‘í•˜ì„¸ìš”.
        objectëŠ” obj_pathë¥¼ ì°¸ê³ í•˜ì—¬ objíŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ ìŠ¤í¬ë¦½íŠ¸ì— ë„£ì–´ì£¼ì„¸ìš”.

        question : {question}
        obj_path : {obj_path} 

        answer:
        """


        formatted_prompt = template.format(question=message, obj_path = save_path)

        '''
        
    elif "rag_all" in fn_call:
        template = """
        You are a coder for Blender Python program.
        ì‚¬ìš©ìê°€ ìš”ì²­í•œ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ì´ ì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.
        ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•´ë‹¬ë¼ê³  ì‘ë‹µí•´ì£¼ì„¸ìš”.
        
        question: {question},

        answer:
        """

        formatted_prompt = template.format(question=message)

    else:
        template = """
        You are a coder for Blender Python program.
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ì§ˆë¬¸ì´ ì½”ë“œ ìƒì„± ìš”ì²­ì¸ ê²½ìš° ì§ˆë¬¸ì„ ì¢€ ë” êµ¬ì²´ì ìœ¼ë¡œ í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ì„¸ìš”.
        ì§ˆë¬¸ì´ ì½”ë“œ ìƒì„± ìš”ì²­ì´ ì•„ë‹Œ ê²½ìš°ì—ë„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ í•´ì£¼ì„¸ìš”.

        question: {question},

        answer:
        """

        formatted_prompt = template.format(question=message)




    #============== R A G ==============


    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€ëœ í…œí”Œë¦¿ ì •ë³´ì™€ í•¨ê»˜ ì—…ë°ì´íŠ¸
    history_langchain_format.append(SystemMessage(content=formatted_prompt))
    
    # ê¸°ì¡´ì˜ ëŒ€í™” ê¸°ë¡ì„ ì²˜ë¦¬
    for human, ai in history:
        history_langchain_format.append(HumanMessage(content=human))
        history_langchain_format.append(AIMessage(content=ai))

    # ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
    history_langchain_format.append(HumanMessage(content=message))

    # LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±
    gpt_response = llm(history_langchain_format)

    # MCP ì„œë²„ ì „ì†¡
    await send_final_prompt(gpt_response.content) 

    return gpt_response.content


def search_in_db(query, vector_db, k=5):
    """
    ë²¡í„° DBì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    """
    # HuggingFaceEmbeddingsì„ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = embeddings.embed_query(query)
    
    # ë²¡í„° DBì—ì„œ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ kê°œì˜ ë¬¸ì„œ ë°˜í™˜
    results = vector_db.similarity_search_by_vector(query_embedding, k)
    return results



# FastAPI ì„œë²„ì— ë¦¬í€˜ìŠ¤íŠ¸ë¥¼ ë³´ë‚´ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
async def txt2img_request(endpoint_url: str, data: dict, save_path: str):
    # íƒ€ì„ì•„ì›ƒ ì„¤ì • (ì˜ˆ: 60ì´ˆë¡œ ì„¤ì •)
    timeout = httpx.Timeout(60.0)  # íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ì„¤ì •

    async with httpx.AsyncClient(timeout=timeout) as client:
        # FastAPI ì„œë²„ì— POST ìš”ì²­ì„ ë³´ëƒ„
        response = await client.post(endpoint_url, json=data)
        print(f"request ì™„ë£Œ")

        # ë¹„ë™ê¸°ì ìœ¼ë¡œ 20ì´ˆ ëŒ€ê¸°
        await asyncio.sleep(20)
        print(f"timeout 20 ì™„ë£Œ")

        # ì‘ë‹µ ìƒíƒœ ì½”ë“œ í™•ì¸
        if response.status_code == 200:
            print(f"response ì™„ë£Œ")
            # ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            with open(save_path, 'wb') as f:
                f.write(response.content)  # ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥
            print(f"ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ : {save_path}")

            # ì„±ê³µì ì¸ ì‘ë‹µ ë°˜í™˜
            return {"message": "Image generated successfully", "image_path": save_path}




# ë¹„ë™ê¸° ìš”ì²­ í•¨ìˆ˜
async def obj_generate_request(endpoint_url: str, object_name: str, save_path: str):
    data = {"object": object_name}
    timeout = httpx.Timeout(60.0)

    async with httpx.AsyncClient(timeout=timeout) as client:
        response = await client.post(endpoint_url, json=data)
        print("ğŸ” ìš”ì²­ ì „ì†¡ ì™„ë£Œ")

        # ë¹„ë™ê¸° ëŒ€ê¸°
        await asyncio.sleep(5)
        print("â±ï¸ ëŒ€ê¸° ì™„ë£Œ")

        if response.status_code == 200:
            result = response.json()
            mesh_text = result.get("mesh", "")
            
            with open(save_path, 'w', encoding='utf-8') as f:
                f.write(mesh_text)
            
            print(f"âœ… .obj ì €ì¥ ì™„ë£Œ: {save_path}")
            return {"message": "OBJ mesh generated", "file_path": save_path}
        else:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {response.status_code} - {response.text}")
            return {"error": f"Request failed with status {response.status_code}"}



# ë¹„ë™ê¸° ìš”ì²­ í•¨ìˆ˜ (ìµœì¢… í”„ë¡¬í”„íŠ¸ ì „ì†¡ìš©)
async def send_final_prompt(prompt: str):
    url = mcp_url
    data = {"prompt": prompt}

    async with httpx.AsyncClient() as client:
        try:
            response = await client.post(url, json=data)
            print("ğŸ” MCP ì„œë²„ í”„ë¡¬í”„íŠ¸ ì „ì†¡ ì™„ë£Œ")

            if response.status_code == 200:
                result = response.json()
                print("âœ… MCP ì„œë²„ ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ : ", result)
                return result
            else:
                print(f"âŒ MCP ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {response.status_code} - {response.text}")
                return {"error": f"Request failed with status {response.status_code}"}
        except Exception as e:
            print(f"ğŸš¨ MCP ì„œë²„ ì˜ˆì™¸ ë°œìƒ: {e}")
            return {"error": str(e)}

# ì¸í„°í˜ì´ìŠ¤ ìƒì„±
gr.ChatInterface(
    fn=response,   # LLM ì‘ë‹µì²˜ë¦¬ ì½œë°±í•¨ìˆ˜ ì„¤ì •
    textbox=gr.Textbox(placeholder="Talk", container=False, scale=7),
    chatbot=gr.Chatbot(height=500),
    title="Blender-MCP",
    theme="soft",
).launch(share=True)
